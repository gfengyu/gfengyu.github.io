<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Fengyu Gao</title>

    <meta name="author" content="Fengyu Gao">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <!-- <link rel="icon" href="images/fengyu.JPG" type="image/x-icon"> -->
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Fengyu Gao
                </p>
                <p>I'm a third-year PhD student in the Department of Computer Science at the University of Virginia, advised by Prof. <a href="https://jing-yang7.github.io">Jing Yang</a>. Previously, I received my Bachelor's degree in Computer Science and Technology from University of Science and Technology of China (USTC) in 2022.
                </p>
                <p style="text-align:center">
                  <a href="mailto:wan6jj@virginia.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=ppyx_LkAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/fengyu-gao-779713261">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:25%;max-width:25%">
                <a href="images/fengyu.JPG"><img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/fengyu.JPG" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interests span several topics in machine learning, including **trustworthy machine learning**, **federated learning**, and **reinforcement learning**. Recently, I have been particularly interested in the **trustworthiness of
LLMs**, including (but not limited to) privacy issues during inference (e.g., in-context learning) and post-training (e.g., preference alignment).
                </p>

                <p>(* indicates equal contribution)</p>

                <p><a href="https://arxiv.org/abs/2410.12085">Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning</a></p>
                <p style="margin-left:1em;"><strong>Fengyu Gao</strong>*, Ruida Zhou*, Tianhao Wang, Cong Shen, Jing Yang</p>
                <p style="margin-left:1em;"><em>In International Conference on Learning Representations (<strong>ICLR</strong>) 2025</em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/gfengyu/AdaDPSyn">[Code]</a></p>
                <p style="margin-left:1em;">
                  TL;DR: Differentially private synthetic few-shot example generation for in-context learning by leveraging data clustering patterns.
                </p>

                <p><a href="https://arxiv.org/abs/2409.19092">Federated Online Prediction from Experts with Differential Privacy: Separations and Regret Speed-ups</a></p>
                <p style="margin-left:1em;"><strong>Fengyu Gao</strong>, Ruiquan Huang, Jing Yang</p>
                <p style="margin-left:1em;"><em>In Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>) 2024</em></p>
                <p style="margin-left:1em;">
                  TL;DR: Differentially private federated online prediction from experts, achieving regret speed-up under stochastic and special oblivious adversaries, and establishing lower bounds.
                </p>



                <p><a href="https://arxiv.org/abs/2312.15023">Federated Q-Learning: Linear Regret Speedup with Low Communication Cost</a></p>
                <p style="margin-left:1em;">Zhong Zheng, <strong>Fengyu Gao</strong>, Lingzhou Xue, Jing Yang</p>
                <p style="margin-left:1em;"><em>In International Conference on Learning Representations (<strong>ICLR</strong>) 2024</em></p>
                <p style="margin-left:1em;">
                  TL;DR: Model-free federated Q-learning for tabular MDPs, achieving linear regret speed-up with logarithmic communication cost.
                </p>


              </td>
            </tr>
          </tbody></table>
          

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
                <p style="margin-left:1em;"><strong>Reviewer:</strong> ICLR 2025</p>
                <p style="margin-left:1em;"><strong>Teaching Assistant:</strong> Algebraic Structure, Spring 2021, USTC; Analog and Digital Circuits, Fall 2020, USTC</p>

              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Thank <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing the source code of his homepage.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
